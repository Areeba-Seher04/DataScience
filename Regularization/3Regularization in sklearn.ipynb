{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  L1 REGULARIZATION (simple model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data_reg.csv, you'll find data for a bunch of points including six predictor variables and one outcome variable. Use sklearn's Lasso class to fit a linear regression model to the data, while also using L1 regularization to control for model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25664</td>\n",
       "      <td>2.04978</td>\n",
       "      <td>-6.23640</td>\n",
       "      <td>4.71926</td>\n",
       "      <td>-4.26931</td>\n",
       "      <td>0.20590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.89012</td>\n",
       "      <td>-0.37511</td>\n",
       "      <td>6.14979</td>\n",
       "      <td>4.94585</td>\n",
       "      <td>-3.57844</td>\n",
       "      <td>0.00640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.09784</td>\n",
       "      <td>0.98120</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>5.85805</td>\n",
       "      <td>0.28297</td>\n",
       "      <td>-0.20626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39034</td>\n",
       "      <td>-3.06861</td>\n",
       "      <td>-5.63488</td>\n",
       "      <td>6.43941</td>\n",
       "      <td>0.39256</td>\n",
       "      <td>-0.07084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.84727</td>\n",
       "      <td>-0.15922</td>\n",
       "      <td>11.41246</td>\n",
       "      <td>7.52165</td>\n",
       "      <td>1.69886</td>\n",
       "      <td>0.29022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-4.58240</td>\n",
       "      <td>-1.27825</td>\n",
       "      <td>7.55098</td>\n",
       "      <td>8.83930</td>\n",
       "      <td>-3.80318</td>\n",
       "      <td>0.04386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-10.00364</td>\n",
       "      <td>2.66002</td>\n",
       "      <td>-4.26776</td>\n",
       "      <td>-3.73792</td>\n",
       "      <td>-0.72349</td>\n",
       "      <td>-0.24617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-4.32624</td>\n",
       "      <td>-2.30314</td>\n",
       "      <td>-8.16044</td>\n",
       "      <td>4.46366</td>\n",
       "      <td>-3.33569</td>\n",
       "      <td>-0.01655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.90167</td>\n",
       "      <td>-0.15858</td>\n",
       "      <td>-10.43466</td>\n",
       "      <td>4.89762</td>\n",
       "      <td>-0.64606</td>\n",
       "      <td>-0.14519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.43213</td>\n",
       "      <td>2.41613</td>\n",
       "      <td>2.49949</td>\n",
       "      <td>-8.03891</td>\n",
       "      <td>-1.64164</td>\n",
       "      <td>-0.63444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1         2        3        4        5\n",
       "0    1.25664  2.04978  -6.23640  4.71926 -4.26931  0.20590\n",
       "1   -3.89012 -0.37511   6.14979  4.94585 -3.57844  0.00640\n",
       "2    5.09784  0.98120  -0.29939  5.85805  0.28297 -0.20626\n",
       "3    0.39034 -3.06861  -5.63488  6.43941  0.39256 -0.07084\n",
       "4    5.84727 -0.15922  11.41246  7.52165  1.69886  0.29022\n",
       "..       ...      ...       ...      ...      ...      ...\n",
       "95  -4.58240 -1.27825   7.55098  8.83930 -3.80318  0.04386\n",
       "96 -10.00364  2.66002  -4.26776 -3.73792 -0.72349 -0.24617\n",
       "97  -4.32624 -2.30314  -8.16044  4.46366 -3.33569 -0.01655\n",
       "98  -1.90167 -0.15858 -10.43466  4.89762 -0.64606 -0.14519\n",
       "99   2.43213  2.41613   2.49949 -8.03891 -1.64164 -0.63444\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Split the data so that the six predictor features (first six columns) are stored in X, \n",
    "and the outcome feature (last column) is stored in y.\n",
    "'''\n",
    "train_data = pd.read_csv('data_reg.csv',header=None)\n",
    "X = train_data.iloc[:,:-1]\n",
    "y = train_data.iloc[:,-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit data using linear regression with Lasso regularization\n",
    " - Create an instance of sklearn's Lasso class and assign it to the variable lasso_reg. You don't need to set any parameter values: use the default values for this code.\n",
    " - Use the Lasso object's .fit() method to fit the regression model onto the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the linear regression model with lasso regularization.\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "#Fit the model.\n",
    "lasso_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the coefficients of the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          2.35793224  2.00441646 -0.05511954 -3.92808318  0.        ]\n"
     ]
    }
   ],
   "source": [
    "#Retrieve and print out the coefficients from the regression model.\n",
    "reg_coef = lasso_reg.coef_\n",
    "print(reg_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For which of the predictor features(X) has the lasso regularization step zeroed the corresponding coefficient?\n",
    "##### As you can see that answer is 1st one and last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  L1 REGULARIZATION (complex/polynomial model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it will gives 4 degree polynomial object\n",
    "poly_feat = PolynomialFeatures(degree = 4)\n",
    "\n",
    "#fit your x a/c to these polynomial features\n",
    "X_poly = poly_feat.fit_transform(X)\n",
    "# pd.DataFrame(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=2000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=1, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the linear regression model with lasso regularization.\n",
    "lasso_reg1 = Lasso(max_iter=2000,tol=1)\n",
    "#Fit the model.\n",
    "lasso_reg1.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  0.00000000e+00  3.00406732e+00  1.78623934e+00\n",
      " -2.30803479e-01 -3.71384816e+00  0.00000000e+00 -1.95309557e-02\n",
      " -0.00000000e+00 -1.46557498e-03  4.36299806e-03 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -2.45727864e-02 -1.01845590e-02\n",
      "  0.00000000e+00  0.00000000e+00  2.16431684e-03  4.85729985e-04\n",
      " -0.00000000e+00  0.00000000e+00  3.10117551e-03 -7.60551752e-03\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -1.79015576e-04 -6.60026412e-03  2.79593429e-03  2.13528975e-03\n",
      " -1.85709370e-03  1.02252022e-01 -8.94814737e-04 -0.00000000e+00\n",
      " -2.71088626e-03  5.56251694e-03  0.00000000e+00 -7.99245716e-05\n",
      " -8.05436897e-05  2.53141781e-03  0.00000000e+00 -2.98481699e-05\n",
      "  2.48767581e-03  0.00000000e+00 -1.77469974e-03  0.00000000e+00\n",
      " -0.00000000e+00 -1.41137351e-03 -5.42600005e-03  1.96914071e-03\n",
      " -9.85972197e-03  0.00000000e+00 -2.52634618e-04  2.47306094e-04\n",
      "  4.12408140e-04  0.00000000e+00 -2.05851988e-04  0.00000000e+00\n",
      " -0.00000000e+00  1.79069871e-04 -0.00000000e+00 -0.00000000e+00\n",
      "  8.85595786e-04  6.16512582e-04 -2.45551578e-03  3.91079530e-02\n",
      "  2.06486701e-04 -4.28287203e-04 -0.00000000e+00  5.28995512e-03\n",
      " -0.00000000e+00 -0.00000000e+00  1.97048809e-04 -2.17888673e-04\n",
      "  3.12484685e-02  4.50154136e-04  0.00000000e+00  0.00000000e+00\n",
      " -4.83654915e-03  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  6.97679476e-05 -5.44836823e-04  1.17250213e-04 -3.13609307e-05\n",
      " -9.25542836e-05  2.35137914e-03  1.58983545e-03 -3.57551378e-04\n",
      "  4.41112857e-05  8.74331344e-05 -0.00000000e+00  1.78243468e-05\n",
      "  1.09107883e-04 -2.20059626e-04  9.36258443e-06 -8.98379269e-05\n",
      "  9.51699641e-05  8.55839364e-05  9.64122705e-06  0.00000000e+00\n",
      "  0.00000000e+00 -6.79864680e-04 -0.00000000e+00  8.32102812e-05\n",
      "  4.67344448e-04  0.00000000e+00  9.44499432e-05  6.41790420e-05\n",
      "  1.40408169e-03  0.00000000e+00  7.99617040e-05  1.11875476e-03\n",
      " -0.00000000e+00 -1.09987694e-03 -0.00000000e+00  0.00000000e+00\n",
      " -9.74191826e-06  9.65759281e-06 -1.22422879e-04 -6.35556234e-04\n",
      " -3.43086780e-05 -9.80202585e-05 -3.45295391e-03  2.86928653e-04\n",
      " -0.00000000e+00 -0.00000000e+00  3.95157958e-06  2.36673880e-05\n",
      "  7.56733082e-04  8.13851204e-05  0.00000000e+00  0.00000000e+00\n",
      " -4.52758043e-05 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -1.42154252e-03 -1.79079826e-03  3.48940113e-04 -4.71194899e-05\n",
      "  0.00000000e+00  1.42377137e-04  1.98581612e-04 -3.81913229e-04\n",
      "  0.00000000e+00  3.36359350e-05  8.43926368e-06 -2.78835488e-03\n",
      "  2.24652045e-03 -0.00000000e+00 -0.00000000e+00 -1.06389254e-04\n",
      "  2.90640893e-04  6.65648014e-04 -0.00000000e+00  2.70061512e-05\n",
      " -1.71133453e-04 -9.84070791e-03  5.36837135e-04 -0.00000000e+00\n",
      " -0.00000000e+00 -2.23426539e-05  3.54557924e-05  1.58731004e-03\n",
      " -2.01882444e-04  0.00000000e+00  0.00000000e+00  3.36604029e-04\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  7.36115505e-06\n",
      " -5.01957179e-05  7.50021355e-05  3.37826591e-05 -6.88448690e-06\n",
      "  2.56017761e-05 -9.80553159e-04  2.37078531e-04 -0.00000000e+00\n",
      " -0.00000000e+00  4.35401818e-06 -3.06333003e-05  9.27049820e-04\n",
      " -1.26314465e-04  5.76089776e-03  0.00000000e+00 -1.90154988e-04\n",
      "  1.87037014e-03  0.00000000e+00  0.00000000e+00  1.23148373e-06\n",
      "  1.69083049e-06  2.41186486e-04 -5.76670399e-06 -8.92376098e-04\n",
      " -6.70392956e-03 -3.09427218e-05  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.54791055e-04 -1.46379338e-03  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "reg_coef1 = lasso_reg1.coef_\n",
    "print(reg_coef1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And here you can see that many co-efficients are 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for l2 regularization you can use Ridge class instead of Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHICH ONE TO USE (L1 V/S L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>L1</th>\n",
    "    <th>L2</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Compuationally inefficient(unless data is sparse) , seems easy because no square values but actually absulate values are hard to differentiate</td>\n",
    "    <td>Compuationally efficient because (square values have very nice derivatives)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>Most special benefit is FEATURE SELECTION. e.g You have 1000 of data and only 10 are relevant. it will detect irrelevant column and make them 0.As you saw in above code how regularization will remove features from a model (by setting their coefficients to zero)</td>\n",
    "      <td>No feature selection (treat all columns similar)</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
